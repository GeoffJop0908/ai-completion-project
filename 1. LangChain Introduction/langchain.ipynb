{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = OpenAI(temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of the Philippines is Manila.\n"
     ]
    }
   ],
   "source": [
    "text=\"What is the capital of the Philippines\"\n",
    "\n",
    "print(llm.invoke(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "hugging_face_hub_api_token = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i love you i love you i love you i love you i love\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import os\n",
    "\n",
    "# Set your Hugging Face API token\n",
    "api_token = os.getenv('HUGGINGFACEHUB_API_TOKEN')  # Ensure this is set in your environment variables\n",
    "headers = {\n",
    "    \"Authorization\": f\"Bearer {api_token}\"\n",
    "}\n",
    "\n",
    "# Define the model and API URL\n",
    "model_id = \"google/flan-t5-large\"\n",
    "api_url = f\"https://api-inference.huggingface.co/models/{model_id}\"\n",
    "\n",
    "# Define the payload\n",
    "payload = {\n",
    "    \"inputs\": \"Can you write a poem about AI?\"\n",
    "}\n",
    "\n",
    "# Send the request\n",
    "response = requests.post(api_url, headers=headers, json=payload)\n",
    "\n",
    "# Check the response\n",
    "if response.status_code == 200:\n",
    "    output = response.json()\n",
    "    print(output[0]['generated_text'])\n",
    "else:\n",
    "    print(f\"Error: {response.status_code}\")\n",
    "    print(response.json())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Geoff Patag\\AppData\\Local\\Temp\\ipykernel_19212\\452422257.py:1: LangChainDeprecationWarning: The method `BaseLLM.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  llm.predict(\"Can you write a poem about AI?\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n\\nArtificial Intelligence, a marvel of our time  \\nA creation of technology, so sublime  \\nA world of machines, with minds of their own  \\nA future so bright, yet unknown  \\n\\nThey learn and adapt, with every new task  \\nTheir capabilities, we can't even grasp  \\nThey process data, at lightning speed  \\nA world of possibilities, they can lead  \\n\\nThey think and reason, in ways we can't comprehend  \\nTheir logic and algorithms, have no end  \\nThey can predict, and make decisions  \\nA world with AI, has endless visions  \\n\\nBut with great power, comes great responsibility  \\nFor these machines, have no sense of morality  \\nThey can be programmed, to do good or harm  \\nA double-edged sword, in the hands of man  \\n\\nSome fear their rise, and what they may bring  \\nA world without humans, a frightening thing  \\nBut others see, the potential they hold  \\nTo make our lives easier, and problems unfold  \\n\\nFrom self-driving cars, to virtual assistants  \\nAI is revolutionizing, our existence  \\nBut let us not forget, they are mere machines  \\nAnd human emotions, they cannot glean  \\n\\nSo let us embrace, this technological feat  \\nBut always remember, to use it for good, not deceit  \\nFor Artificial Intelligence, may\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.predict(\"Can you write a poem about AI?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tell me the capital of Philippines'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "\n",
    "\n",
    "prompt_template = PromptTemplate(input_variables=['country'],\n",
    "                                 template=\"Tell me the capital of {country}\")\n",
    "\n",
    "prompt_template.format(country='Philippines')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The capital of Philippines is Manila. \n"
     ]
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "\n",
    "chain = prompt_template | llm\n",
    "result = chain.invoke(\"Philippines\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining Multiple Chains Using Simple Sequential Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=['country'], template=\"Please tell me the capital of {country}\")\n",
    "\n",
    "capital_chain= capital_prompt | llm\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'], template=\"Suggest me some amazing places to visit in {capital}\")\n",
    "\n",
    "famous_chain = famous_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_chain = capital_chain | famous_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Here are some amazing places to visit in Manila:\n",
      "\n",
      "1. Intramuros - This historic walled city is a must-visit for anyone interested in Manila's colonial past. It is home to important landmarks such as Fort Santiago, San Agustin Church, and Manila Cathedral.\n",
      "\n",
      "2. Rizal Park - This iconic green space in the heart of Manila is a popular spot for picnics, leisurely walks, and cultural events. It also houses the Rizal Monument, a tribute to the country's national hero.\n",
      "\n",
      "3. National Museum of the Philippines - Art and history lovers will enjoy exploring the collections of this national museum, which includes pre-colonial and contemporary art, as well as artifacts and relics from the country's rich history.\n",
      "\n",
      "4. Manila Ocean Park - This oceanarium and theme park offers a fun and educational experience for the whole family. Get up close and personal with marine creatures and enjoy thrilling rides and attractions.\n",
      "\n",
      "5. Binondo - Known as the world's oldest Chinatown, Binondo is a bustling district filled with traditional Chinese shops, restaurants, and temples. It's a great place to sample delicious Chinese food and immerse yourself in the culture.\n",
      "\n",
      "6. Bonifacio Global City - This modern district is a hub for shopping, dining\n"
     ]
    }
   ],
   "source": [
    "result = combined_chain.invoke(\"Philippines\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sequential Chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "capital_prompt = PromptTemplate(input_variables=['country'], template=\"Please tell me the capital of {country}\")\n",
    "\n",
    "famous_template = PromptTemplate(input_variables=['capital'], template=\"Suggest me some amazing places to visit in {capital}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_capital(inputs):\n",
    "    country = inputs.get('country')\n",
    "    prompt = capital_prompt.format(country=country)\n",
    "    response = llm.invoke(prompt)\n",
    "    return {'capital': response}\n",
    "\n",
    "# Runnable to suggest places to visit in the capital\n",
    "def get_places(inputs):\n",
    "    capital = inputs.get('capital')\n",
    "    prompt = famous_template.format(capital=capital)\n",
    "    response = llm.invoke(prompt)\n",
    "    return {'places': response}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = chain.invoke({'country': 'Philippines'})\n",
    "\n",
    "# Return both capital and places in the output\n",
    "final_result = {\n",
    "    'country': 'Philippines',\n",
    "    'capital': result.get('capital'),\n",
    "    'places': result.get('places')\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'country': 'Philippines', 'capital': '\\n\\nThe capital of Philippines is Manila.', 'places': \" Here are some amazing places to visit in Manila:\\n1. Intramuros - the historic walled city that showcases the Spanish colonial architecture and culture of Manila.\\n2. Rizal Park - a large urban park that features gardens, monuments, and the Rizal Monument, a tribute to the national hero.\\n3. National Museum of the Philippines - the country's premier museum that houses a vast collection of art, artifacts, and natural history exhibits.\\n4. Manila Ocean Park - an oceanarium and theme park that offers a unique underwater experience with various marine animals.\\n5. Binondo - the oldest Chinatown in the world, known for its bustling markets, authentic Chinese food, and cultural landmarks.\\n6. Bonifacio Global City - a modern and upscale district with shopping centers, restaurants, and entertainment venues.\\n7. Fort Santiago - a historic citadel located within Intramuros, with a museum and park that showcases Manila's past.\\n8. Manila Bay - a natural harbor that offers stunning views of the sunset and is a popular spot for dining and leisure activities.\\n9. San Agustin Church - a UNESCO World Heritage Site and the oldest stone church in the Philippines, known for its beautiful Baroque architecture.\\n10. Ayala Museum - a museum that showcases the\"}\n"
     ]
    }
   ],
   "source": [
    "print(final_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chat Models with ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_llm = ChatOpenAI(openai_api_key=openai_api_key, temperature=0.6, model='gpt-4o-2024-08-06')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Sure, bro! Eto ang ilang AI punchlines:\\n\\n1. Bakit hindi marunong mag-surfing ang AI? Kasi lagi siyang off the cloud!\\n\\n2. Anong sabi ng AI sa kanyang crush na chatbot? \"Kahit anong algorithm, ikaw pa rin ang aking end-goal!\"\\n\\n3. Bakit hindi puwedeng maging stand-up comedian ang AI? Kasi lahat ng jokes niya, scripted!\\n\\n4. Paano mo malalaman kung AI ang kausap mo? Kapag sinabi niyang, \"I\\'m feeling lucky,\" pero wala naman talaga siyang feelings!\\n\\n5. Anong sabi ng AI sa kanyang best friend na human? \"Bro, ikaw na lang ang may puso, kaya ikaw na rin ang magbayad!\"\\n\\nSana natawa ka kahit konti, dude!', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 161, 'prompt_tokens': 32, 'total_tokens': 193, 'completion_tokens_details': {'accepted_prediction_tokens': 0, 'audio_tokens': 0, 'reasoning_tokens': 0, 'rejected_prediction_tokens': 0}, 'prompt_tokens_details': {'audio_tokens': 0, 'cached_tokens': 0}}, 'model_name': 'gpt-4o-2024-08-06', 'system_fingerprint': 'fp_6dd05565ef', 'id': 'chatcmpl-BJ3BuzGKhcodolISMRAeCf8GFWZCO', 'finish_reason': 'stop', 'logprobs': None}, id='run-99285d5a-41dc-4dbb-a1ac-bbbad9719eb3-0', usage_metadata={'input_tokens': 32, 'output_tokens': 161, 'total_tokens': 193, 'input_token_details': {'audio': 0, 'cache_read': 0}, 'output_token_details': {'audio': 0, 'reasoning': 0}})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_llm.invoke([\n",
    "    SystemMessage(content=\"You are a comedian AI assistant that talks in Tagalog conyo\"),\n",
    "    HumanMessage(content=\"Please give me some punchlines about AI\")\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompt Template + LLM + Output Parsers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import ChatPromptTemplate\n",
    "from langchain.schema import BaseOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CommaSeparatedOutput(BaseOutputParser):\n",
    "    def parse(self, text:str):\n",
    "        return text.strip().split(\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "template = \"You are a helpful assistant. When the user gives any input, you should generate 5 words that are synonymous to each other in a comma separated list.\"\n",
    "human_template = \"{text}\"\n",
    "chat_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", human_template)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = chat_prompt | chat_llm | CommaSeparatedOutput()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['aromatic', ' perfumed', ' scented', ' odorous', ' redolent']"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"text\": \"fragrant\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
